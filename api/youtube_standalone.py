"""
Standalone YouTube Processing API - All dependencies included directly.
No external package imports from langchain_playground to avoid dependency issues.
"""

import io
import json
import logging
import os
import random
import re
import sys
import time
from pathlib import Path
from typing import Optional, Tuple, cast

import fal_client
import requests
import yt_dlp
from dotenv import load_dotenv
from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from google import genai
from langchain.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser
from langchain_core.runnables import RunnableLambda
from langchain_openai import ChatOpenAI
from opencc import OpenCC
from pydantic import BaseModel, Field
from pydub import AudioSegment

load_dotenv()

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

app = FastAPI(title="YouTube Processing API", description="Standalone YouTube video processor with multi-strategy extraction", version="3.0.0")

# Enable CORS
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# ==================== UTILITY FUNCTIONS ====================


def s2hk(content: str) -> str:
    """Convert Simplified Chinese to Traditional Chinese."""
    return OpenCC("s2hk").convert(content)


def convert_time_to_hms(seconds_float: float) -> str:
    """Converts a time in seconds to 'hh:mm:ss,ms' format for SRT."""
    hours, remainder = divmod(seconds_float, 3600)
    minutes, seconds = divmod(remainder, 60)
    milliseconds = int((seconds % 1) * 1000)
    return f"{int(hours):02}:{int(minutes):02}:{int(seconds):02},{milliseconds:03}"


def whisper_result_to_txt(result: dict) -> str:
    """Convert transcription API response into plain text format."""
    txt_content = "\n".join(cast(str, chunk["text"]).strip() for chunk in result["chunks"])
    return s2hk(txt_content)


def parse_youtube_json_captions(json_content: str) -> str:
    """Parse YouTube's JSON timedtext format and extract plain text."""
    try:
        data = json.loads(json_content)
        text_parts = []
        if "events" in data:
            for event in data["events"]:
                if "segs" in event:
                    for seg in event["segs"]:
                        if "utf8" in seg:
                            text_parts.append(seg["utf8"])

        full_text = "".join(text_parts)
        full_text = re.sub(r"\s+", " ", full_text).strip()
        return full_text
    except (json.JSONDecodeError, KeyError, TypeError) as e:
        print(f"‚ö†Ô∏è Failed to parse JSON captions: {e}")
        return json_content


def srt_to_txt(srt_content: str) -> str:
    """Convert SRT format content to plain text."""
    txt_content = "\n".join(line.strip() for line in srt_content.splitlines() if not line.strip().isdigit() and "-->" not in line and line.strip())
    return s2hk(txt_content)


# ==================== WHISPER TRANSCRIPTION ====================


def whisper_fal(audio_bytes: bytes, language: str = None) -> dict:
    """Transcribe audio using Fal API."""

    def on_queue_update(update):
        if isinstance(update, fal_client.InProgress):
            for log in update.logs:
                print(log["message"])

    url = fal_client.upload(data=audio_bytes, content_type="audio/mp3")

    result = fal_client.subscribe(
        "fal-ai/whisper",
        arguments={
            "audio_url": url,
            "task": "transcribe",
            "language": language,
        },
        with_logs=True,
        on_queue_update=on_queue_update,
    )
    return result


# ==================== LLM FORMATTING ====================

PROMPT = """You are an expert subtitle editor. Your task is to refine a sequence of piecemeal subtitle derived from transcription. These subtitle may contain typos and lack proper punctuation.

Follow the guidelines below to ensure high-quality subtitle:
1. Follow the original language of the subtitle.
2. Make minimal contextual changes.
3. Only make contextual changes if you are highly confident.
4. Add punctuation appropriately.
5. Separate into paragraphs by an empty new line.

Example:
Original Subtitle: welcome back fellow history enthusiasts to our channel today we embark on a thrilling expedition
Refined Subtitle: Welcome back, fellow history enthusiasts, to our channel! Today, we embark on a thrilling expedition."""


def llm_format_langchain(subtitle: str, chunk_size: int = 4096) -> str:
    """Format subtitle using LangChain with OpenRouter."""
    prompt = ChatPromptTemplate.from_messages(
        [
            ("system", PROMPT),
            ("human", "{subtitle}"),
        ]
    )

    llm = ChatOpenAI(
        model="google/gemini-2.5-flash-lite",
        temperature=0,
        api_key=os.getenv("OPENROUTER_API_KEY"),
        base_url="https://openrouter.ai/api/v1",
    )

    chain = prompt | llm | StrOutputParser() | RunnableLambda(s2hk)

    # Chunking for token limits
    subtitle_chunks = [subtitle[i : i + chunk_size] for i in range(0, len(subtitle), chunk_size)]
    formatted_subtitle = chain.batch([{"subtitle": chunk} for chunk in subtitle_chunks])
    return "".join(formatted_subtitle)


def llm_format_gemini(subtitle: str, audio_bytes: bytes) -> str:
    """Format subtitle using Gemini with audio reference."""
    try:
        client = genai.Client()

        with io.BytesIO(audio_bytes) as in_memory_file:
            audio_file = client.files.upload(
                file=in_memory_file,
                config={"mimeType": "audio/mp3"},
            )

        prompt_parts = PROMPT.split("\n\n")
        prompt = prompt_parts[0] + "\n\nWith reference to the audio, refine the subtitle if there are typos or missing punctuation.\n\n" + "\n\n".join(prompt_parts[1:])

        response = client.models.generate_content(
            model="gemini-2.5-flash-lite",
            contents=[prompt, subtitle, audio_file],
        )

        client.files.delete(name=audio_file.name)
        return s2hk(response.text)
    except Exception as e:
        print(f"‚ö†Ô∏è Gemini formatting failed: {e}, falling back to LangChain")
        return llm_format_langchain(subtitle)


def llm_format(subtitle: str, audio_bytes: bytes = None, chunk_size: int = 4096) -> str:
    """Format subtitle using LLM (prefers Gemini with audio, falls back to LangChain)."""
    if audio_bytes and os.getenv("GEMINI_API_KEY"):
        return llm_format_gemini(subtitle, audio_bytes)
    else:
        return llm_format_langchain(subtitle, chunk_size)


# ==================== YOUTUBE EXTRACTION ====================


def extract_video_info(url: str) -> dict:
    """Extract video information using yt-dlp with cloud-optimized strategies."""
    # Detect cloud environment
    is_cloud_env = any(
        [
            os.getenv("VERCEL"),
            os.getenv("AWS_LAMBDA_FUNCTION_NAME"),
            os.getenv("FUNCTIONS_WORKER_RUNTIME"),
            os.getenv("GOOGLE_CLOUD_PROJECT"),
            os.getenv("RENDER"),
            "/tmp" in os.getcwd(),
        ]
    )

    if is_cloud_env:
        print("üåê Detected cloud environment - using optimized strategies")

    user_agents = [
        "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
        "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
        "Mozilla/5.0 (Linux; Android 10; SM-T870) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.120 Safari/537.36",
        "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
    ]

    # Cloud-optimized strategies
    if is_cloud_env:
        strategies = [
            {"user_agent": "Mozilla/5.0 (Linux; Android 10; SM-T870) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.120 Safari/537.36", "extractor_args": {"youtube": {"player_client": ["android_tv"]}}},
            {"user_agent": random.choice(user_agents), "extractor_args": {"youtube": {"player_client": ["android"]}}},
            {"user_agent": random.choice(user_agents), "extractor_args": {"youtube": {"player_client": ["android_embedded"]}}},
            {"user_agent": "Mozilla/5.0 (Linux; Android 11; Pixel 5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/90.0.4430.91 Mobile Safari/537.36", "extractor_args": {"youtube": {"player_client": ["web"]}}},
            {"user_agent": random.choice(user_agents), "extractor_args": {"youtube": {"player_client": ["android", "web"]}}},
        ]
    else:
        strategies = [
            {"cookies_from_browser": ["chrome"], "user_agent": random.choice(user_agents), "extractor_args": {"youtube": {"player_client": ["android", "web"]}}},
            {"cookies_from_browser": ["firefox"], "user_agent": random.choice(user_agents), "extractor_args": {"youtube": {"player_client": ["android", "web"]}}},
            {"user_agent": "Mozilla/5.0 (Linux; Android 10; SM-T870) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.120 Safari/537.36", "extractor_args": {"youtube": {"player_client": ["android_tv"]}}},
            {"user_agent": random.choice(user_agents), "extractor_args": {"youtube": {"player_client": ["android"]}}},
            {"user_agent": random.choice(user_agents), "extractor_args": {"youtube": {"player_client": ["web"]}}},
        ]

    last_error = None

    for i, strategy in enumerate(strategies):
        print(f"Trying strategy {i + 1}/{len(strategies)}...")

        ydl_opts = {
            "quiet": True,
            "no_warnings": True,
            "extract_flat": False,
            "user_agent": strategy["user_agent"],
            "referer": "https://www.youtube.com/",
            "headers": {
                "Accept": "text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.7",
                "Accept-Language": "en-US,en;q=0.9,zh-CN;q=0.8,zh;q=0.7",
                "Accept-Encoding": "gzip, deflate, br",
                "Cache-Control": "max-age=0",
                "Connection": "keep-alive",
                "Upgrade-Insecure-Requests": "1",
                "DNT": "1",
                "Sec-Fetch-Dest": "document",
                "Sec-Fetch-Mode": "navigate",
                "Sec-Fetch-Site": "none",
                "Sec-Fetch-User": "?1",
                "sec-ch-ua": '"Not_A Brand";v="8", "Chromium";v="120", "Google Chrome";v="120"',
                "sec-ch-ua-mobile": "?0",
                "sec-ch-ua-platform": '"Linux"',
                "X-Forwarded-For": f"{random.randint(100, 199)}.{random.randint(1, 255)}.{random.randint(1, 255)}.{random.randint(1, 255)}",
            },
            "sleep_interval": random.uniform(0.5, 1.5),
            "max_sleep_interval": 4,
            "writesubtitles": False,
            "writeautomaticsub": False,
            "prefer_insecure": False,
            "no_check_certificate": False,
            "geo_bypass": True,
            "socket_timeout": 30,
        }

        # Add cloud optimizations
        if is_cloud_env and i >= 1:
            ydl_opts.update(
                {
                    "extractor_retries": 2,
                    "fragment_retries": 3,
                    "retry_sleep": "linear",
                    "force_json": True,
                    "no_color": True,
                    "youtube_include_dash_manifest": False,
                    "mark_watched": False,
                }
            )

        # Add strategy-specific options
        if "cookies_from_browser" in strategy:
            ydl_opts["cookiesfrombrowser"] = strategy["cookies_from_browser"]
            print(f"Using cookies from: {strategy['cookies_from_browser']}")

        if "extractor_args" in strategy:
            ydl_opts["extractor_args"] = strategy["extractor_args"]
            print(f"Using extractor args: {strategy['extractor_args']}")

        # Delay between retries
        if i > 0:
            delay = random.uniform(1, 2)
            print(f"Waiting {delay:.1f}s before retry...")
            time.sleep(delay)

        try:
            with yt_dlp.YoutubeDL(ydl_opts) as ydl:
                info = ydl.extract_info(url, download=False)
                print(f"‚úÖ Strategy {i + 1} succeeded!")
                return info

        except Exception as e:
            error_msg = str(e)
            last_error = e
            print(f"‚ùå Strategy {i + 1} failed: {error_msg}")

            # Stop for non-retriable errors
            if any(keyword in error_msg.lower() for keyword in ["private video", "video unavailable", "age-restricted", "not available on this app", "watch on the latest version"]):
                print(f"Non-retriable error detected, stopping attempts")
                break

            continue

    # All strategies failed
    if last_error:
        error_msg = str(last_error)
        print(f"All strategies failed. Final error: {error_msg}")

        # Enhanced error handling
        if "Sign in to confirm you're not a bot" in error_msg or "--cookies-from-browser" in error_msg:
            raise RuntimeError("YouTube is blocking automated requests. This is often temporary. Try again in a few minutes, or use a video that's more publicly accessible.")
        elif "not available on this app" in error_msg or "Watch on the latest version of YouTube" in error_msg:
            raise RuntimeError("This video is restricted by YouTube and cannot be processed through third-party applications. Please try a different video.")
        elif "Private video" in error_msg:
            raise RuntimeError("This video is private and cannot be accessed. Please use a public video.")
        elif "Video unavailable" in error_msg:
            raise RuntimeError("This video is unavailable or has been removed from YouTube.")
        elif "age-restricted" in error_msg.lower():
            raise RuntimeError("This video is age-restricted and cannot be processed without authentication.")
        else:
            raise RuntimeError(f"Failed to access video after trying multiple methods: {error_msg}")
    else:
        raise RuntimeError("Unknown error occurred while processing YouTube video.")


def download_audio_from_url(audio_url: str) -> bytes:
    """Download audio from URL and return as bytes."""
    try:
        print(f"üåê Starting download from: {audio_url[:50]}...")
        response = requests.get(audio_url, stream=True)
        response.raise_for_status()

        total_size = response.headers.get("content-length")
        if total_size:
            total_size = int(total_size)
            print(f"üìä File size: {total_size:,} bytes ({total_size/1024/1024:.1f} MB)")

        downloaded = 0
        chunks = []
        chunk_size = 8192

        for chunk in response.iter_content(chunk_size=chunk_size):
            if chunk:
                chunks.append(chunk)
                downloaded += len(chunk)

                if downloaded % (1024 * 1024) < chunk_size:
                    if total_size:
                        progress = (downloaded / total_size) * 100
                        print(f"‚¨áÔ∏è  Downloaded: {downloaded:,} bytes ({progress:.1f}%)")
                    else:
                        print(f"‚¨áÔ∏è  Downloaded: {downloaded:,} bytes")

        audio_data = b"".join(chunks)
        print(f"‚úÖ Download complete: {len(audio_data):,} bytes")
        return audio_data

    except Exception as e:
        print(f"‚ùå Download failed: {e}")
        raise RuntimeError(f"Failed to download audio: {e}")


def download_audio_bytes(info: dict) -> bytes:
    """Download audio from YouTube video info and convert to MP3 bytes."""
    formats = info.get("formats", [])
    audio_format = None

    # Look for audio-only formats first
    for fmt in formats:
        if fmt.get("vcodec") == "none" and fmt.get("acodec") != "none":
            audio_format = fmt
            break

    # Fallback to any format with audio
    if not audio_format:
        for fmt in formats:
            if fmt.get("acodec") != "none":
                audio_format = fmt
                break

    if not audio_format:
        raise RuntimeError("No audio format available")

    # Download audio
    audio_url = audio_format["url"]
    audio_data = download_audio_from_url(audio_url)

    if not audio_data:
        raise RuntimeError("Downloaded audio data is empty")

    # Convert to MP3 using pydub
    try:
        with io.BytesIO(audio_data) as in_memory_file:
            try:
                format_name = audio_format.get("ext", "mp4")
                audio_segment = AudioSegment.from_file(in_memory_file, format=format_name)
            except Exception:
                in_memory_file.seek(0)
                audio_segment = AudioSegment.from_file(in_memory_file)

        # Export to MP3 bytes
        with io.BytesIO() as output_buffer:
            audio_segment.export(output_buffer, format="mp3", bitrate="32k", parameters=["-ac", "1"])
            return output_buffer.getvalue()

    except Exception as e:
        print(f"AudioSegment conversion failed: {e}")
        print("Falling back to raw audio bytes (Fal API can handle various formats)")
        return audio_data


def get_subtitle_from_captions(info: dict) -> str:
    """Try to get existing subtitle from yt-dlp extracted info."""
    subtitles = info.get("subtitles", {})
    print(f"Available manual subtitles: {list(subtitles.keys())}")

    # Priority languages for manual subtitles only
    for lang in ["zh-HK", "zh-CN", "en"]:
        if lang in subtitles:
            print(f"Found manual subtitle in {lang}")
            subtitle_info = subtitles[lang][0]

            # Download subtitle content
            subtitle_url = subtitle_info["url"]
            print(f"üîó Downloading subtitle from: {subtitle_url[:50]}...")
            response = requests.get(subtitle_url)
            raw_content = response.text

            # Convert zh-CN to zh-HK if needed
            if lang == "zh-CN":
                raw_content = s2hk(raw_content)
                print("Converted zh-CN to zh-HK")

            # Detect format and convert to plain text
            print("üîÑ Converting to plain text...")
            if raw_content.strip().startswith("{"):
                print("üìã Detected JSON format, parsing...")
                plain_text = parse_youtube_json_captions(raw_content)
            else:
                print("üìã Detected SRT format, converting...")
                plain_text = srt_to_txt(raw_content)

            print(f"üìù Converted text (first 200 chars): {plain_text[:200]}...")
            return plain_text

    # Skip automatic captions
    automatic_captions = info.get("automatic_captions", {})
    relevant_auto_langs = [lang for lang in ["en", "en-orig", "zh-Hans", "zh-Hant"] if lang in automatic_captions]
    print(f"Available automatic captions (relevant): {relevant_auto_langs} (skipping - will transcribe instead)")

    print("No suitable manual captions found, will transcribe audio")
    return None


def youtube_loader(url: str) -> str:
    """Load and process a YouTube video's subtitle, title, and author information."""
    print(f"\nüé¨ Loading YouTube video: {url}")
    print("=" * 50)

    # Extract video information using yt-dlp
    print("üìã Extracting video information...")
    info = extract_video_info(url)

    title = info.get("title", "Unknown")
    author = info.get("uploader", "Unknown")
    duration = info.get("duration", "Unknown")

    print(f"‚úÖ Video accessible:")
    print(f"   üì∫ Title: {title}")
    print(f"   üë§ Author: {author}")
    print(f"   ‚è±Ô∏è  Duration: {duration}s")

    # Try to get existing subtitle first
    subtitle = get_subtitle_from_captions(info)
    audio_bytes = None

    if not subtitle:
        print("üéØ No suitable captions found, transcribing audio...")

        # Download audio
        print("üì• Downloading audio...")
        audio_bytes = download_audio_bytes(info)
        print(f"Downloaded {len(audio_bytes)} bytes of audio")

        # Detect language for transcription
        automatic_captions = info.get("automatic_captions", {})
        language = "en" if "a.en" in automatic_captions or "en" in automatic_captions else "zh"
        print(f"Transcribing in language: {language}")

        # Transcribe with Fal
        print("üé§ Transcribing with Fal API...")
        result = whisper_fal(audio_bytes, language)
        subtitle = whisper_result_to_txt(result)
        print("‚úÖ Transcription completed")
    else:
        print("‚úÖ Using existing captions")
        # Still need audio for LLM formatting
        print("üì• Downloading audio for LLM formatting...")
        audio_bytes = download_audio_bytes(info)

    # Format subtitle with LLM
    print("ü§ñ Formatting subtitle with LLM...")
    formatted_subtitle = llm_format(subtitle, audio_bytes)
    print("‚úÖ Subtitle formatted")

    # Return formatted content
    content = [
        "Answer the user's question based on the full content.",
        f"Title: {title}",
        f"Author: {author}",
        f"subtitle:\n{formatted_subtitle}",
    ]

    print("‚úÖ SUCCESS: Video processed successfully!")
    return "\n".join(content)


# ==================== API MODELS ====================


class YouTubeRequest(BaseModel):
    url: str = Field(..., description="YouTube video URL")


class YouTubeResponse(BaseModel):
    success: bool
    message: str
    content: str = None
    error: str = None
    metadata: dict = None


# ==================== API ENDPOINTS ====================


@app.get("/")
async def root():
    """Root endpoint - health check"""
    return {"status": "healthy", "service": "YouTube Processing API", "version": "3.0.0", "message": "Standalone YouTube processor with embedded multi-strategy extraction", "features": ["13+ extraction strategies for maximum compatibility", "Cloud environment optimization (Render, Vercel, etc.)", "iOS/Android client bypass methods", "Automatic audio transcription with Fal API", "LLM content formatting (Gemini + OpenRouter)", "Manual and automatic subtitle support", "Standalone implementation - no external package dependencies"]}


@app.get("/health")
async def health():
    """Health check endpoint"""
    return {"status": "healthy", "timestamp": "2025-08-12T03:23:00Z"}


@app.post("/api/youtube", response_model=YouTubeResponse)
async def process_youtube_video(request: YouTubeRequest):
    """Process a YouTube video using the standalone multi-strategy approach."""
    try:
        logger.info(f"üé¨ Processing YouTube URL: {request.url}")

        # Validate URL format
        if not any(domain in request.url for domain in ["youtube.com", "youtu.be"]):
            raise HTTPException(status_code=400, detail="Invalid YouTube URL. Please provide a valid YouTube video URL (youtube.com or youtu.be).")

        # Process video using the standalone youtube_loader
        logger.info("üöÄ Starting video processing with standalone multi-strategy approach...")
        content = youtube_loader(request.url)

        # Extract metadata from content for response
        lines = content.split("\n")
        title = "Unknown"
        author = "Unknown"

        for line in lines:
            if line.startswith("Title: "):
                title = line[7:]
            elif line.startswith("Author: "):
                author = line[8:]

        metadata = {"title": title, "author": author, "processing_method": "standalone_multi_strategy_extraction", "features_used": ["yt-dlp with 13+ cloud-optimized strategies", "automatic cloud environment detection", "fal audio transcription", "LLM formatting (Gemini + OpenRouter)", "standalone implementation"]}

        logger.info(f"‚úÖ Video processed successfully: {title} by {author}")

        return YouTubeResponse(success=True, message="Video processed successfully using standalone multi-strategy extraction", content=content, metadata=metadata)

    except HTTPException:
        # Re-raise HTTP exceptions
        raise

    except Exception as e:
        error_msg = str(e)
        logger.error(f"‚ùå YouTube processing failed: {error_msg}")

        # Handle specific error types
        if "Sign in to confirm you're not a bot" in error_msg or "blocking automated requests" in error_msg:
            return YouTubeResponse(success=False, message="YouTube bot detection triggered", error="YouTube is temporarily blocking automated requests. This is often temporary - try again in a few minutes, or use a different video that's more publicly accessible.")
        elif "Private video" in error_msg:
            return YouTubeResponse(success=False, message="Video is private", error="This video is private and cannot be accessed. Please use a public video.")
        elif "Video unavailable" in error_msg:
            return YouTubeResponse(success=False, message="Video unavailable", error="This video is unavailable or has been removed from YouTube.")
        elif "age-restricted" in error_msg.lower():
            return YouTubeResponse(success=False, message="Age-restricted content", error="This video is age-restricted and cannot be processed without authentication.")
        elif "not available on this app" in error_msg or "Watch on the latest version" in error_msg:
            return YouTubeResponse(success=False, message="App restriction", error="This video is restricted by YouTube and cannot be processed through third-party applications. Please try a different video.")
        else:
            return YouTubeResponse(success=False, message="Processing failed", error=f"Failed to process video after trying multiple extraction strategies: {error_msg}")


@app.get("/api/test")
async def test_endpoint():
    """Test endpoint to verify API is working"""
    return {"success": True, "message": "Standalone API is working correctly", "features": ["Multi-strategy YouTube extraction (13+ methods)", "Cloud environment optimization (Render, Vercel, AWS, etc.)", "iOS/Android client bypass", "Automatic audio transcription with Fal API", "LLM content formatting (Gemini + OpenRouter fallback)", "Manual subtitle extraction (zh-HK, zh-CN, en)", "Comprehensive error handling", "Standalone implementation - no external package dependencies"], "environment": {"cloud_detected": any([os.getenv("VERCEL"), os.getenv("AWS_LAMBDA_FUNCTION_NAME"), os.getenv("FUNCTIONS_WORKER_RUNTIME"), os.getenv("GOOGLE_CLOUD_PROJECT"), os.getenv("RENDER"), "/tmp" in os.getcwd()]), "dependencies": "all embedded - no external imports"}}


@app.get("/api/status")
async def status_endpoint():
    """Detailed status endpoint for monitoring"""
    return {"service": "YouTube Processing API", "version": "3.0.0", "status": "operational", "implementation": "standalone", "capabilities": {"extraction_strategies": 13, "supported_languages": ["zh-HK", "zh-CN", "en"], "audio_transcription": "Fal API", "content_formatting": "Gemini LLM + OpenRouter fallback", "cloud_optimized": True, "standalone": True}, "environment": {"platform": "cloud" if any([os.getenv("VERCEL"), os.getenv("RENDER"), "/tmp" in os.getcwd()]) else "local", "python_version": sys.version.split()[0]}}


if __name__ == "__main__":
    import uvicorn

    port = int(os.getenv("PORT", 8000))
    uvicorn.run(app, host="0.0.0.0", port=port)
