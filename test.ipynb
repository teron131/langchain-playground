{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a445676",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from langchain_openai import ChatOpenAI\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "model = \"openai/gpt-5-mini\"\n",
    "temperature = 0\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    model=model,\n",
    "    api_key=os.getenv(\"OPENROUTER_API_KEY\"),\n",
    "    base_url=\"https://openrouter.ai/api/v1\",\n",
    "    temperature=temperature,\n",
    "    reasoning_effort=\"medium\",\n",
    "    include_response_headers=True,\n",
    "    use_responses_api=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92a0fddf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-08 12:05:28,562 - INFO - HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "response = llm.invoke(\"Explain gradient descent\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc22d635",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-08 12:04:32,376 - WARNING - USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(\"**Explaining gradient descent**\\n\\nThe user is asking for a general explanation of gradient descent, so I want to be concise yet thorough. I should consider including the intuition behind it, math, and its variants like batch, stochastic, and mini-batch approaches. I'll discuss the learning rate, convergence issues, and potential problems such as local minima or saddle points. It would be good to mention the algorithm steps and provide examples like linear regression, alongside relevant formulas in plain text. A simple 1D example or illustrating it with a quadratic function would also help make the concept accessible. I'll summarize with practical tips.**Structuring gradient descent explanation**\\n\\nI’m thinking about a structured approach for explaining gradient descent. I want to provide a short definition and intuitive idea followed by the mathematical formulation for minimizing a function f(θ) and the update rule. It’s essential to explain the learning rate and its consequences. Then, I can discuss variants like batch, stochastic, and mini-batch methods, alongside convergence properties, improvements like momentum and Adam, and practical tips such as feature scaling.\\n\\nI might include a simple 1D example to demonstrate minimizing f(x)=x^2 step-by-step while explaining pseudo-code as well.\",\n",
       " 'What it is (short): Gradient descent is an iterative optimization method for finding the minimum of a function by repeatedly moving parameters in the direction that decreases the function most rapidly — the negative gradient.\\n\\nIntuition:\\n- The gradient of a function points in the direction of steepest increase.\\n- To minimize, move a small step opposite the gradient.\\n- Repeat until you reach a (local) minimum.\\n\\nMathematical formulation:\\n- Problem: minimize f(θ) with respect to parameters θ.\\n- Update rule (basic gradient descent):\\n  θ ← θ − α ∇f(θ)\\n  where ∇f(θ) is the gradient and α > 0 is the learning rate (step size).\\n\\nSimple 1-D example:\\n- f(x) = x^2, ∇f = 2x.\\n- Update: x ← x − α (2x) = (1 − 2α) x.\\n- If 0 < α < 1/2, x converges to 0.\\n\\nAlgorithm (pseudo-code):\\n- Initialize θ (random or otherwise).\\n- Repeat until stopping condition:\\n  - compute g = ∇f(θ)\\n  - θ ← θ − α g\\n  - check stopping (small ||g||, small change in f, or max iterations)\\n\\nVariants:\\n- Batch (full) gradient descent: compute gradient on entire dataset each step — stable but expensive for large data.\\n- Stochastic gradient descent (SGD): use gradient from a single random example each step — noisy but cheap and often faster to start improving.\\n- Mini-batch gradient descent: use gradient from a small batch (common in deep learning) — tradeoff between noise and computation.\\n\\nPractical issues and remedies:\\n- Learning rate α:\\n  - Too large → divergence or oscillation.\\n  - Too small → very slow convergence.\\n  - Use schedules (decay), line search, or adaptive optimizers.\\n- Local minima and saddle points:\\n  - For convex functions, any local minimum is global and gradient descent converges (with appropriate α).\\n  - For nonconvex functions (neural nets), gradient descent can get stuck in local minima or saddle points; randomness and momentum help escape saddles.\\n- Ill-conditioning / slow convergence:\\n  - If the curvature (Hessian) varies a lot across directions, plain gradient descent can be slow. Preconditioning, second-order methods (Newton), or adaptive methods help.\\n- Stopping criteria: gradient norm small, objective change small, validation loss stops improving, or fixed iterations.\\n\\nCommon improvements / alternatives:\\n- Momentum: accumulates past gradients to smooth updates and accelerate along consistent directions.\\n- Nesterov momentum: a lookahead variant that can improve convergence speed.\\n- Adaptive methods: AdaGrad, RMSProp, Adam — adjust per-parameter learning rates automatically.\\n- Second-order methods: Newton’s method, quasi-Newton (L-BFGS) use curvature information for faster convergence for smaller problems.\\n\\nTips for practice:\\n- Scale/normalize features when optimizing models (helps condition number).\\n- Start with a reasonable α (try powers of 10) and use decay or adaptive optimizers.\\n- Use mini-batches (e.g., 32–512) for neural networks.\\n- Monitor training and validation loss to detect divergence/overfitting.\\n\\nSummary: Gradient descent is a foundational, simple method for minimizing functions by following the negative gradient. Its success depends on choice of step size, problem conditioning, and appropriate algorithmic variants (SGD, momentum, adaptive optimizers) for the task.')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_playground.llm.openrouter import parse_invoke\n",
    "\n",
    "parse_invoke(response, include_reasoning=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0c60ba87",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"OpenRouter LLM client initialization and configuration.\"\"\"\n",
    "\n",
    "import os\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from langchain_openai import ChatOpenAI\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "model = \"openai/gpt-5-mini\"\n",
    "temperature = 0\n",
    "\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    model=model,\n",
    "    api_key=os.getenv(\"OPENROUTER_API_KEY\"),\n",
    "    base_url=\"https://openrouter.ai/api/v1\",\n",
    "    temperature=temperature,\n",
    "    reasoning_effort=\"medium\",  # Can be \"minimal\", \"low\", \"medium\", or \"high\"\n",
    "    # use_responses_api=True,  # Required for reasoning_effort to work\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7adeeceb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-08 14:45:37,477 - WARNING - USER_AGENT environment variable not set, consider setting it to identify your requests.\n",
      "2025-12-08 14:45:39,188 - INFO - HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessage(content='The image you provided is a screenshot of code (a JSON-like message object with a text prompt and an image URL). It does not show an outdoor scene, sky, or any photographic cues, so I can’t determine the weather from it.\\n\\nIf you want a weather description, please upload a photo that actually shows the scene (sky, landscape, street, etc.) or share metadata (EXIF) from the photo — I can then describe cloudiness, precipitation, lighting, wind clues, etc.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 299, 'prompt_tokens': 652, 'total_tokens': 951, 'completion_tokens_details': {'accepted_prediction_tokens': None, 'audio_tokens': None, 'reasoning_tokens': 192, 'rejected_prediction_tokens': None, 'image_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0, 'video_tokens': 0}, 'cost': 0.00075339, 'is_byok': False, 'cost_details': {'upstream_inference_cost': None, 'upstream_inference_prompt_cost': 0.000163, 'upstream_inference_completions_cost': 0.000598}}, 'model_provider': 'openai', 'model_name': 'openai/gpt-5-mini', 'system_fingerprint': None, 'id': 'gen-1765176338-NIbc6E9u731XcoYfFuxN', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--738ad70c-5f91-432a-bd4e-c873eeda67e8-0', usage_metadata={'input_tokens': 652, 'output_tokens': 299, 'total_tokens': 951, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'reasoning': 192}})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_playground.llm.multimodal import MediaMessage\n",
    "\n",
    "message = MediaMessage(\"input.png\", description=\"Describe the weather in this image\")\n",
    "ai_msg = llm.invoke([message])\n",
    "ai_msg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65699461",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools import tool\n",
    "\n",
    "from langchain_playground.tools.youtube import youtube_loader\n",
    "\n",
    "\n",
    "@tool\n",
    "def scrape_youtube_video(youtube_url: str) -> str:\n",
    "    \"\"\"Scrape a YouTube video and return its transcript and metadata.\n",
    "\n",
    "    This tool extracts the transcript, title, channel, duration, views, likes,\n",
    "    and other metadata from a YouTube video URL.\n",
    "\n",
    "    Args:\n",
    "        youtube_url: The YouTube video URL to scrape (e.g., https://www.youtube.com/watch?v=VIDEO_ID)\n",
    "\n",
    "    Returns:\n",
    "        A formatted string containing video metadata and transcript\n",
    "    \"\"\"\n",
    "    return youtube_loader(youtube_url)\n",
    "\n",
    "\n",
    "tools = [scrape_youtube_video]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77e8cde6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import create_agent\n",
    "\n",
    "# Create a model for the agent (without structured output, as agents handle tool calling)\n",
    "agent_llm = ChatOpenAI(\n",
    "    model=model,\n",
    "    api_key=os.getenv(\"OPENROUTER_API_KEY\"),\n",
    "    base_url=\"https://openrouter.ai/api/v1\",\n",
    "    temperature=temperature,\n",
    "    reasoning_effort=\"medium\",\n",
    "    # extra_body={\"plugins\": [{\"id\": \"web\"}]},\n",
    "    use_responses_api=True,\n",
    ")\n",
    "\n",
    "# Create a simple agent with the YouTube scraper tool\n",
    "youtube_agent = create_agent(\n",
    "    model=agent_llm,\n",
    "    tools=tools,\n",
    "    # system_prompt=\"You are a helpful assistant that can analyze YouTube videos. When given a YouTube URL, use the scrape_youtube_video tool to get the video transcript and metadata, then provide insights or answer questions about the video content.\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4295e3d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-08 12:11:51,274 - INFO - HTTP Request: POST https://openrouter.ai/api/v1/responses \"HTTP/1.1 200 OK\"\n",
      "2025-12-08 12:11:59,745 - INFO - HTTP Request: POST https://openrouter.ai/api/v1/responses \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "# Example: Scrape a YouTube video and ask questions about it\n",
    "# Replace with your own YouTube URL\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "\n",
    "youtube_url = \"https://www.youtube.com/watch?v=dQw4w9WgXcQ\"  # Example URL\n",
    "\n",
    "response = youtube_agent.invoke({\"messages\": [HumanMessage(content=youtube_url)]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08de9761",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('**Crafting a concise response**\\n\\nI\\'ll reply to the user with something like: \"I fetched the video. Metadata: ...\" and then I’ll list the relevant details. I\\'ll also mention that I retrieved the full transcript and lyrics. I think it\\'s a good idea to offer the user some options for what they\\'d like next. I\\'ll keep the answer concise, maybe including the first lines of the lyrics, but that\\'s not strictly necessary. Just need to keep it clear and to the point!',\n",
       " 'I fetched that YouTube video. Summary of what I found:\\n\\n- Title: Rick Astley - Never Gonna Give You Up (Official Video) (4K Remaster)\\n- Channel: Rick Astley\\n- Duration: 3:34\\n- Published: Oct 24, 2009\\n- Views: 1,720,344,092\\n- Likes: 18,668,354\\n- Description: Official video + notes about the song/album, links to Rick Astley’s socials and streaming, plus full lyrics in the description.\\n- Transcript: I retrieved the full transcript/lyrics (the familiar full lyrics are available).\\n\\nWhat would you like me to do with this? Options:\\n- Provide a short summary/analysis of the video\\n- Show the full transcript or a timestamped version\\n- Extract the lyrics (plain text)\\n- Translate the lyrics/transcript to another language\\n- Create captions/subtitles (SRT)\\n- Anything else you have in mind\\n\\nTell me which and I’ll do it.')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parse_invoke(response[\"messages\"][-1], include_reasoning=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
